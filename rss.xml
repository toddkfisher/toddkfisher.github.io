<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title><![CDATA[Writing a Game in Common Lisp and C]]></title>
<description><![CDATA[Writing a Game in Common Lisp and C]]></description>
<link>./</link>
<lastBuildDate>Tue, 30 Jul 2024 16:32:05 -0700</lastBuildDate>
<item>
  <title><![CDATA[Testing Sound Playback]]></title>
  <description><![CDATA[
<p>
<b>Previous livestreams:</b>
</p>

<p>
<a href="https://www.youtube.com/watch?v=49ojU19ruHk">https://www.youtube.com/watch?v=49ojU19ruHk</a>
</p>

<p>
<a href="https://www.youtube.com/watch?v=8zS1ABTCTmo&amp;t=191s">https://www.youtube.com/watch?v=8zS1ABTCTmo&amp;t=191s</a>
</p>

<div id="outline-container-org1539c30" class="outline-2">
<h2 id="org1539c30"><span class="section-number-2">1.</span> TODAY'S AGENDA</h2>
<div class="outline-text-2" id="text-1">
<p>
I  have  a  small  test   program,  <code>simple-playback.c</code>,  which  uses  Miniaudio
(<a href="https://miniaud.io/">https://miniaud.io/</a>)   for  asychronous   sound   playback  and   cancellation.
<code>simple-playback.c</code>  is  a  "wrapper"  around Miniaudio's  low-level  API.   The
low-level  API  must  be  used  to play sound  files  preloaded  into  memory  (see
<a href="2024-07-28-playing-sounds-using-in-memory-blobs.html">Livestream  post 28-July-24</a>)  The wrapper  code in  <code>simple-playback.c</code> will  be
tested today  (hopefully) and I'll  begin moving functions prefixed  with <code>snd_</code>
over to the <code>sound.c</code> module.  <code>sound.c</code> compiles to <code>libsound.so</code>.  Once that's
complete, we should be able to use Lisp/CFFI to call exported functions from the
Lisp REPL.
</p>
</div>
</div>

<div id="outline-container-orga11ca2c" class="outline-2">
<h2 id="orga11ca2c"><span class="section-number-2">2.</span> EXPORTING FUNCTIONS TO LISP</h2>
<div class="outline-text-2" id="text-2">
<p>
A note about what  I mean by "exporting functions to Lisp/CFFI".   I have a Lisp
program <code>cffi-gen.lisp</code> which parses a limited form of C function declarations:
</p>

<p>
<i>&lt;type-name&gt; &lt;function-name&gt; <code>(</code> (<code>void</code> | &lt;parameter-list&gt;) <code>)</code> <code>//</code> <code>EXPORT</code> &lt;newline&gt;</i>
</p>

<p>
and produces the appropriate Lisp/CFFI <code>defcfun</code>.
</p>

<p>
For example, the C function declaration:
</p>

<pre class="example" id="org846334e">

void ui_set_kbd_repeat(uint32_t timeout_ms, uint32_t delay_ms)  // EXPORT

</pre>

<p>
Produces:
</p>

<pre class="example" id="org4d58e0d">
(cffi:defcfun ("ui_set_kbd_repeat" set-kbd-repeat) :void
              (timeout-ms :uint32)
              (delay-ms :uint32))
(export 'set-kbd-repeat)
</pre>

<p>
when run through <code>cffi-gen.lisp</code>.
</p>

<p>
<b>END</b>
</p>
<hr>
</div>
</div>
<div class="taglist"></div>]]></description>
  <link>./2024-07-30-testing-sound-playback.html</link>
  <guid>./2024-07-30-testing-sound-playback.html</guid>
  <pubDate>Tue, 30 Jul 2024 12:54:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Playing Sounds Using In-Memory BLOBS]]></title>
  <description><![CDATA[
<p>
<b>Summary:</b> I  briefly describe how  thread-based resource management is  used in
<del><code>sound.c</code></del> <code>simple-playback.c</code>  and how it  will be modified to  play preloaded
sound files residing in memory.
</p>

<div id="outline-container-org8dbeeb7" class="outline-2">
<h2 id="org8dbeeb7"><span class="section-number-2">1.</span> SOUND PLAYBACK AND RESOURCE MANAGEMENT.</h2>
<div class="outline-text-2" id="text-1">
<p>
<code>Miniaudio</code> has a simple way of playing a sound file:
<code>ma_engine_play_sound()</code> which is adequate for asynchronously loading and
playing sounds.  We would like to preload sounds and play them from memory but
there is no simple high-level function for this.  We must resort to <code>Miniaudio</code>'s
"low-level" API.
</p>

<p>
To play sounds through the low-level API we must:
</p>
<ol class="org-ol">
<li>Create an <code>ma_decoder</code> from a file or block of memory.  The decoder must
be configured for sample format, channel count, and sample rate.</li>
<li>An <code>ma_device</code> must be configured and initialized.  The device contains references
to the decoder created in step 1 as well as a callback function which uses the decoder to
provide <code>Miniaudio</code> with frames (a frame is a set of samples: one per channel).</li>
<li>Finally, we must start the device. This begins playing the sound.</li>
</ol>

<p>
Sound playback can be cancelled with <code>ma_device_uninit()</code> and <code>ma_decoder_uninit()</code> but
this <i>must not happen</i> in the data callback, it must occur in another thread.
To overcome this restriction we have a seperate thread function, <code>snd_cancel_thread()</code>:
which calls <code>ma_(device|decoder)_uninit()</code> when a condition <code>g_cnd_cancel</code> is
signalled.
</p>

<p>
In <code>sound.c</code>,  devices and decoders  are stored in an  array: <code>g_sound_list[]</code>.
Each entry  in <code>g_sound_list[]</code> is a  structure which holds an  "is available"
flag:
</p>

<pre class="example" id="org926f887">
typedef struct
{
  ma_device        s_device;
  ma_device_config s_device_config;
  ma_decoder       s_decoder;
  atomic_bool      s_cancel_sent;
  atomic_bool      s_is_available;
  int              s_idx_sound_list;
} sound_t;

// Array of sound resources.
// IF g_sound_list[i].s_is_available &amp;&amp; !g_sound_list[i].s_cancel_sent THEN:
//
//   slot i may be used as a decoder and device to play a sound.
//
// NOTE that there is no free list of available slots.  The list must be scanned to find
// a free slot i.
#define MAX_SOUNDS 25
sound_t g_sound_list[MAX_SOUNDS];
</pre>

<p>
Sound playback is achieved  with <code>snd_play_file_async()</code> which finds an
index of an available device/decoder and then proceeds with steps 1-3 above.  And
the resources in <code>g_sound_list[</code> <i>&lt;index&gt;</i> <code>]</code> are made unvailable.
</p>

<p>
Cancellation of a sound can occur when a sound has completed playing or during
playback.  <code>snd_cancel_async()</code> places the an index of an entry in <code>g_sound_list[]</code>
onto <code>g_cancel_list[]</code> and signals <code>g_cnd_cancel</code> waking up the <code>snd_cancel_thread()</code>.
A mutex, <code>g_mtx_sound_list</code>, is used to synchronize access to <code>g_sound_list[]</code>
</p>

<pre class="example" id="org522eed9">
// Indices into g_sound_list[] of sounds/resources to be cancelled &amp; freed.
// Only indices stored in g_cancel_list[0] .. g_cancel_list[g_cancel_list_end - 1]
// are valid.
int g_cancel_list_end = 0;
int g_cancel_list[MAX_SOUNDS];

// Synchronize access to g_sound_list[] and g_cancel_list[].
pthread_mutex_t g_mtx_sound_list = PTHREAD_MUTEX_INITIALIZER;
</pre>

<p>
All of this functionality will eventually be used in LISP through <code>CFFI</code>.
</p>
</div>
</div>

<div id="outline-container-org7918bd9" class="outline-2">
<h2 id="org7918bd9"><span class="section-number-2">2.</span> REGION-BASED MEMORY MANAGEMENT</h2>
<div class="outline-text-2" id="text-2">
<p>
We would prefer that our LISP code not call <code>malloc()</code> and <code>free()</code>.  It is expected that
sounds will be loaded into memory when our program starts.
</p>

<p>
<code>stk-alloc.c</code> allocates memory blocks by simply advancing a pointer <code>g_p_next</code> when a
block is requested (<code>stkalloc_get_mem()</code>).  Calling <code>stkalloc_free(p)</code> adjusts <code>g_p_next</code>
to <code>p</code> and so everything allocated after <code>p</code> is released as well.
</p>
</div>
</div>

<div id="outline-container-orgddded59" class="outline-2">
<h2 id="orgddded59"><span class="section-number-2">3.</span> PLAYING SOUNDS PRELOADED IN MEMORY</h2>
<div class="outline-text-2" id="text-3">
<p>
So far all of the code for sound playback lives in a test program, <code>simple-playback.c</code>.
In today's livestream, we will:
</p>
<ol class="org-ol">
<li>Load several sound files into memory using <code>libstackalloc</code>.</li>
<li>Provide some sort of UI for playing and cancelling sounds.</li>
</ol>

<p>
<b>END</b>
</p>
<hr>
</div>
</div>
<div class="taglist"></div>]]></description>
  <link>./2024-07-28-playing-sounds-using-in-memory-blobs.html</link>
  <guid>./2024-07-28-playing-sounds-using-in-memory-blobs.html</guid>
  <pubDate>Sun, 28 Jul 2024 21:34:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[First Blog Post]]></title>
  <description><![CDATA[
<p>
<b>Summary:</b> This is a first test-post.  In the future each of my livestreams
will have a companion blog post here.
</p>

<div id="outline-container-org56fd9d1" class="outline-2">
<h2 id="org56fd9d1"><span class="section-number-2">1.</span> THE PROJECT</h2>
<div class="outline-text-2" id="text-1">
<p>
I'm writing a game in Common Lisp and C (using CFFI).
So far I have:
</p>
<ol class="org-ol">
<li>A basic UI with graphics.</li>
<li>Sounds (played asynchronously).</li>
<li>Simple (region-based) memory management to store sounds, bitmaps, sprites etc.</li>
<li>Some supporting Lisp code.</li>
</ol>
</div>
</div>

<div id="outline-container-org48fab75" class="outline-2">
<h2 id="org48fab75"><span class="section-number-2">2.</span> MODULE (OR PACKAGE) DEPENDENCIES.</h2>
<div class="outline-text-2" id="text-2">

<figure id="orgba75e31">
<img src="modules.jpg" alt="modules.jpg">

<figcaption><span class="figure-number">Figure 1: </span>This diagram shows the approximate structure of the program.</figcaption>
</figure>
</div>
</div>

<div id="outline-container-orgdb080f9" class="outline-2">
<h2 id="orgdb080f9"><span class="section-number-2">3.</span> SOURCE CODE</h2>
<div class="outline-text-2" id="text-3">
<p>
Github repository forthcoming.
</p>

<p>
<b>END</b>
</p>
</div>
</div>
<div class="taglist"></div>]]></description>
  <link>./2024-07-28-first-blog-post.html</link>
  <guid>./2024-07-28-first-blog-post.html</guid>
  <pubDate>Sun, 28 Jul 2024 19:11:00 -0700</pubDate>
</item>
</channel>
</rss>
